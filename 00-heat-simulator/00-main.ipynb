{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Parse data file\n",
    "def file_to_matrix(filename):\n",
    "    m = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            l = []\n",
    "            for num in line.split(' '):\n",
    "                try:\n",
    "                    l.append(float(num))\n",
    "                except:\n",
    "                    pass\n",
    "            m.append(l)\n",
    "    return np.asarray(m)\n",
    "\n",
    "# Scan dataset dir and parse files\n",
    "def dataset_to_matrices(folder):\n",
    "    heatmaps = []\n",
    "    paths = sorted(Path(folder).iterdir(), key=os.path.getmtime)\n",
    "\n",
    "    for path in paths:\n",
    "        path = str(path)\n",
    "        if (path.endswith(\".out\") or path.endswith(\".out\")) and os.path.isfile(path):\n",
    "            m = file_to_matrix(path)\n",
    "            \n",
    "            heatmaps.append(m)\n",
    "    return np.asarray(heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = dataset_to_matrices('dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "def matrix_to_graph(m):\n",
    "\n",
    "    # Step size to move to row\n",
    "    u = []\n",
    "    v = []\n",
    "    STEP_SIZE = m.shape[1]\n",
    "\n",
    "    x = 0\n",
    "    for row in range(m.shape[0]):\n",
    "        for col in range(m.shape[1]):\n",
    "            neighbours = []\n",
    "        \n",
    "            # LEFT\n",
    "            if col > 0: neighbours.append(x - 1)\n",
    "\n",
    "            # RIGHT\n",
    "            if col < STEP_SIZE-1: neighbours.append(x + 1)\n",
    "\n",
    "            # UP\n",
    "            if row > 0: neighbours.append(x - STEP_SIZE)\n",
    "\n",
    "            # DOWN\n",
    "            if row < STEP_SIZE-1: neighbours.append(x + STEP_SIZE)\n",
    "\n",
    "            # Creating edges\n",
    "            for n in neighbours:\n",
    "                u.append(int(x))\n",
    "                v.append(int(n))\n",
    "            \n",
    "            x += 1\n",
    "\n",
    "    # Graph creation\n",
    "    edges = torch.tensor(u), torch.tensor(v)\n",
    "    return dgl.graph(edges) #.to('cuda:0')\n",
    "\n",
    "def matrix_to_node_features(m):\n",
    "    return torch.tensor([[c] for c in m.flatten()]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Graph(num_nodes=260100, num_edges=1038360,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "matrix_to_graph(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = matrix_to_graph(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = matrix_to_node_features(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        ...,\n",
       "        [0.9600],\n",
       "        [0.9700],\n",
       "        [0.9900]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "node_features"
   ]
  },
  {
   "source": [
    "## GNN Construction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating thge GCN Functions\n",
    "\n",
    "# Message passing function: from features -> aggregate -> message\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "\n",
    "# Aggregation function (reduce): from all messages -> sum -> compute nodes\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolutional Layer\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "        # simple linear layer\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            # Stores features data into 'h'\n",
    "            g.ndata['h'] = feature\n",
    "            # Apply graph convolution\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            # Obtain final node features\n",
    "            h = g.ndata['h']\n",
    "            # Apply linear layer\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Using GCNLayers\n",
    "        # 1 node feature (each node)\n",
    "        self.layer1 = GCNLayer(1, 16)\n",
    "        self.layer2 = GCNLayer(16, 1)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "\n",
    "        # Continuous output\n",
    "        x = F.relu(self.layer1(g, features))\n",
    "        x = self.layer2(g, x)\n",
    "        return x\n",
    "\n",
    "net = Net().to('cuda:0')"
   ]
  },
  {
   "source": [
    "## It's training time!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/diego/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/diego/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00000 | Loss 0.9388 | Time(s) nan\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00001 | Loss 0.3585 | Time(s) nan\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00002 | Loss 0.0637 | Time(s) nan\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00003 | Loss 0.0222 | Time(s) 0.8010\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00004 | Loss 0.1308 | Time(s) 0.8048\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00005 | Loss 0.2447 | Time(s) 0.7932\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00006 | Loss 0.2698 | Time(s) 0.8005\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00007 | Loss 0.2580 | Time(s) 0.8007\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00008 | Loss 0.1422 | Time(s) 0.8078\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00009 | Loss 0.0679 | Time(s) 0.8058\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00010 | Loss 0.0156 | Time(s) 0.8099\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00011 | Loss 0.0049 | Time(s) 0.8065\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00012 | Loss 0.0280 | Time(s) 0.8075\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00013 | Loss 0.0641 | Time(s) 0.8058\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00014 | Loss 0.0909 | Time(s) 0.8054\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00015 | Loss 0.0951 | Time(s) 0.8058\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00016 | Loss 0.0812 | Time(s) 0.8073\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00017 | Loss 0.0459 | Time(s) 0.8058\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00018 | Loss 0.0284 | Time(s) 0.8065\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00019 | Loss 0.0112 | Time(s) 0.8046\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00020 | Loss 0.0121 | Time(s) 0.8056\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00021 | Loss 0.0233 | Time(s) 0.8045\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00022 | Loss 0.0351 | Time(s) 0.8052\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00023 | Loss 0.0398 | Time(s) 0.8039\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00024 | Loss 0.0351 | Time(s) 0.8028\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00025 | Loss 0.0239 | Time(s) 0.8030\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00026 | Loss 0.0113 | Time(s) 0.8024\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00027 | Loss 0.0035 | Time(s) 0.8030\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00028 | Loss 0.0030 | Time(s) 0.8037\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00029 | Loss 0.0080 | Time(s) 0.8026\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00030 | Loss 0.0163 | Time(s) 0.8032\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00031 | Loss 0.0202 | Time(s) 0.8026\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00032 | Loss 0.0192 | Time(s) 0.8031\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00033 | Loss 0.0138 | Time(s) 0.8027\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00034 | Loss 0.0076 | Time(s) 0.8031\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00035 | Loss 0.0029 | Time(s) 0.8025\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00036 | Loss 0.0021 | Time(s) 0.8029\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00037 | Loss 0.0049 | Time(s) 0.8022\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00038 | Loss 0.0082 | Time(s) 0.8017\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00039 | Loss 0.0096 | Time(s) 0.8024\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00040 | Loss 0.0083 | Time(s) 0.8033\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00041 | Loss 0.0053 | Time(s) 0.8031\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00042 | Loss 0.0023 | Time(s) 0.8035\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00043 | Loss 0.0014 | Time(s) 0.8031\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00044 | Loss 0.0030 | Time(s) 0.8036\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00045 | Loss 0.0036 | Time(s) 0.8035\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00046 | Loss 0.0061 | Time(s) 0.8042\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00047 | Loss 0.0054 | Time(s) 0.8040\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00048 | Loss 0.0039 | Time(s) 0.8038\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00049 | Loss 0.0023 | Time(s) 0.8041\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00050 | Loss 0.0017 | Time(s) 0.8038\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00051 | Loss 0.0022 | Time(s) 0.8040\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00052 | Loss 0.0027 | Time(s) 0.8044\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00053 | Loss 0.0034 | Time(s) 0.8041\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00054 | Loss 0.0029 | Time(s) 0.8048\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00055 | Loss 0.0026 | Time(s) 0.8046\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00056 | Loss 0.0013 | Time(s) 0.8050\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00057 | Loss 0.0013 | Time(s) 0.8045\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00058 | Loss 0.0019 | Time(s) 0.8048\n",
      "*************\n",
      "Epoch 00000 | Heatmap 00059 | Loss 0.0023 | Time(s) 0.8044\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "# 1 shot\n",
    "for epoch in range(1):\n",
    "    \n",
    "    dur = []\n",
    "    for i in range(heatmaps.shape[0] - 1):\n",
    "\n",
    "        if i >= 3:\n",
    "            t0 = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        h = heatmaps[i]\n",
    "        h_next = heatmaps[i+1]\n",
    "\n",
    "        # h -> input\n",
    "        g = matrix_to_graph(h).to('cuda:0')\n",
    "        features = matrix_to_node_features(h).to('cuda:0')\n",
    "\n",
    "        y_hat = net(g, features)\n",
    "\n",
    "        # h_next -> prediction\n",
    "        h_next = torch.tensor([[c] for c in h_next.flatten()]).float().to('cuda:0')\n",
    "\n",
    "        # Compute mse_loss\n",
    "        loss = F.mse_loss(y_hat, h_next)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        print(\"*************\\nEpoch {:05d} | Heatmap {:05d} | Loss {:.4f} | Time(s) {:.4f}\".format(\n",
    "                epoch, i, loss.item(), np.mean(dur)))\n",
    "\n",
    "        #print(\"{}\\n{}\".format(y_hat, h_next))"
   ]
  },
  {
   "source": [
    "## Plotting the results (real vs. prediction)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for heatmap in heatmaps:\n",
    "\n",
    "    # Real\n",
    "    #plt.matshow(heatmaps[x+1], cmap='hot', label='real')\n",
    "    plt.imsave(f\"animation/real/heat{x:03d}.png\", heatmaps[x+1], cmap='hot')\n",
    "    #plt.title(\"Real\")\n",
    "\n",
    "    # Prediction\n",
    "    h = heatmaps[x]\n",
    "\n",
    "    g = matrix_to_graph(h).to('cuda:0')\n",
    "    features = matrix_to_node_features(h).to('cuda:0')\n",
    "    h_hat = net(g, features).detach().cpu().clone().numpy()\n",
    "    h_hat = h_hat.reshape(-1, 510)\n",
    "\n",
    "\n",
    "    #plt.matshow(h_hat, cmap='hot', label='prediction')\n",
    "    plt.imsave(f\"animation/prediction/heat{x:03d}.png\", h_hat, cmap='hot')\n",
    "    #plt.title(\"Prediction\")\n",
    "\n",
    "    x += 1\n",
    "    if x == heatmaps.shape[0]-2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}